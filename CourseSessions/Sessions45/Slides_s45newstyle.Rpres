Session 5-6, Clustering and Segmentation (Technical Slides)
========================================================
author : T. Evgeniou, INSEAD


```{r include=FALSE}
# let's make the data into data.matrix classes so that we can easier visualize them
local_directory <- "."
source(paste(local_directory,"../../AnalyticsLibraries/library.R", sep="/"))
source(paste(local_directory,"../../AnalyticsLibraries/heatmapOutput.R", sep = "/"))

datafile_name="Mall_Visits" # do not add .csv at the end! make sure the data are numeric!!!! check your file!
report_file = "Report_s45"
slides_file = "Slides_s45"
segmentation_attributes_used = c(2:7) 
profile_attributes_used = c(2:9) # for boats use c(2:82), for Mall_Visits use c(2:9)
numb_clusters_used = 3 # for boats possibly use 5, for Mall_Visits use 3
heatmin = 0.1
profile_with = "hclust"
distance_used="euclidean"
hclust_method = "ward"
kmeans_method = "Lloyd"
MIN_VALUE=0.5
max_data_report = 50 # can also chance in server.R
ProjectData <- read.csv(paste(paste(local_directory, "data", sep="/"), paste(datafile_name,"csv", sep="."), sep = "/")) # ProjectData=data.matrix(ProjectData) 
if (datafile_name == "Boats")
  colnames(ProjectData)<-gsub("\\."," ",colnames(ProjectData))
segmentation_attributes_used = unique(sapply(segmentation_attributes_used,function(i) min(ncol(ProjectData), max(i,1))))
profile_attributes_used = unique(sapply(profile_attributes_used,function(i) min(ncol(ProjectData), max(i,1))))
ProjectData_segment=ProjectData[,segmentation_attributes_used]
ProjectData_profile=ProjectData[,profile_attributes_used]
# this is the file name where the CLUSTER_IDs of the observations will be saved
cluster_file = paste(paste(local_directory,"data", sep="/"),paste(paste(datafile_name,"cluster", sep="_"), "csv", sep="."), sep="/")

### TO EDIT DEPENDING ON VERSION
if (require(shiny) == FALSE) 
  install.packages("shiny")

```

Clustering and Segmentation
========================================================
  
  
```{r include=FALSE}
## using dummy data to recreate cluster segmentation graphics
library(vegan)
require(vegan)
data(dune)
# kmeans
kclus <- kmeans(dune,centers= 4, iter.max=1000)
# distance matrix
dune_dist <- dist(dune,method=distance_used)
# Multidimensional scaling
cmd <- cmdscale(dune_dist)
```

```{r fig.width=12, fig.height=6, message=FALSE, echo=FALSE, fig.align='center', warning=FALSE, fig=TRUE}
# plot MDS, with colors by groups from kmeans
groups <- levels(factor(kclus$cluster))
ordiplot(cmd, type = "n")
cols <- c("steelblue", "darkred", "darkgreen", "pink")
for(i in seq_along(groups)){
  points(cmd[factor(kclus$cluster) == groups[i], ], col = cols[i], pch = 16)
  }

# add spider and hull
ordispider(cmd, factor(kclus$cluster), label = TRUE)
ordihull(cmd, factor(kclus$cluster), lty = "dotted")
```


 What is Clustering and Segmentation?
========================================================


  
<br>
<br>
<br>

Processes and tools to organize data in a few segments, with data being as similar as possible within each segment, and as different as possible across segments


 Example Usage
========================================================

<br>
<br>

- Market Segmentation

- Co-Moving Asset Classes

- Geo-demographic segmentation

- Recommender Systems

- Text Mining


A Segmentation Process
========================================================


<br>

1. Confirm data is metric
2. Scale the  data (Optional)
3. Select Segmentation Variables
4. Define similarity measure
5. Visualize Pair-wise Distances 
6. Method and Number of Segments
7. Profile and interpret the segments 
8. Robustness Analysis


 Example Data: Market Research Survey
========================================================


```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
# let's make the data into data.matrix classes so that we can easier visualize them
ProjectData_segment = data.matrix(ProjectData_segment)
ProjectData_profile = data.matrix(ProjectData_profile)
ProjectData = data.matrix(ProjectData)
```

V1: Shopping is fun (scale 1-7)

V2: Shopping is bad for your budget (scale 1-7)

V3: I combine shopping with eating out (scale 1-7)

V4: I try to get the best buys while shopping (scale 1-7)

V5: I don't care about shopping (scale 1-7)

V6: You can save lot of money by comparingprices (scale 1-7)

Income: the household income of the respondent (in dollars)

Mall.Visits: how often they visit the mall (scale 1-7)



Step 1: Confirm data is metric
========================================================


<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
show_data = data.frame(round(ProjectData_segment,2))
show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Variables"
colnames (dfnew)<-change
dfnew = as.data.frame(dfnew)
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
print(m1,'chart')
```
</div>
</div>
</div>


 Step 2: Scale the  data (Optional)
========================================================

<br>

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
show_data = data.frame(round(my_summary(ProjectData_segment),2))
#show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Variables"
colnames (dfnew)<-change
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
print(m1,'chart')
```
</div>
</div>
</div>


 Data Standardization: Example Code
========================================================

<br>
<br>

```{r, results='asis'}
ProjectData_segment_scaled=apply(ProjectData_segment,2, function(r) {
  if (sd(r)!=0) { 
    res=(r-mean(r))/sd(r) 
    } else { 
      res=0*r; res
      }
  })
```

 Standardized Data: Summary Statistics
========================================================


<br>

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
show_data = data.frame(round(my_summary(ProjectData_segment_scaled),2))
#show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Variables"
colnames (dfnew)<-change
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
print(m1,'chart')
```
</div>
</div>
</div>


Step 3. Select Segmentation Variables
========================================================

<br>

The choice of the variables used for clustering is critically important 
<br>
<br>

Tpically we use different variables for segmentation (the "segmentation variables") and different ones for profiling (the "profiling variables")

<br>
<br>

Remember: Segmentation is an iterative process

Step 4. Define similarity measure
========================================================


Defining what we mean when we say "similar" or "different" observations is a key part of cluster analysis which often requires a lot of contextual knowledge and creativity 

<br>
<br>


There are literally thousands of rigorous mathematical definitions of distance between observations/vectors

<br>
<br>

The user can manually define such distance metrics

Distances across our data using the Euclidean distance
========================================================


Pairwise Distances between the first 5 observations using The Euclidean Distance Metric

```{r include=FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE}
euclidean_pairwise <- as.matrix(dist(head(ProjectData_segment, 5), method="euclidean"))
euclidean_pairwise <- euclidean_pairwise*lower.tri(euclidean_pairwise) + euclidean_pairwise*diag(euclidean_pairwise) + 10e10*upper.tri(euclidean_pairwise)
euclidean_pairwise[euclidean_pairwise==10e10] <- NA
```

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, fig.align='center', results='asis'}
print(xtable(euclidean_pairwise, caption="", digits=1), type="html", html.table.attributes = "class='table table-striped table-hover table-bordered'", caption.placement="top", comment = FALSE, include.rownames = FALSE)
```
</div>
</div>
</div>

 Distances across our data using the Manhattan distance
========================================================

Pairwise Distances between the first 5 observations using The Manhattan Distance Metric

```{r include=FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE}
manhattan_pairwise <- as.matrix(dist(head(ProjectData_segment, 5), method="manhattan"))
manhattan_pairwise <- manhattan_pairwise*lower.tri(manhattan_pairwise) + manhattan_pairwise*diag(manhattan_pairwise) + 10e10*upper.tri(manhattan_pairwise)
manhattan_pairwise[manhattan_pairwise==10e10] <- NA
```

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, fig.align='center', results='asis'}
print(xtable(manhattan_pairwise, caption="", digits=1), type="html", html.table.attributes = "class='table table-striped table-hover table-bordered'", caption.placement="top", comment = FALSE, include.rownames = FALSE)
```
</div>
</div>
</div>


 Manually Defined Distances: an Example
========================================================

<br>
<br>
<br>

```{r ,results='asis'}
My_Distance_function<-function(x,y){sum(abs(x-y)>2)}
```

 Manually Defined Distances: an Example
========================================================

Pairwise Distances between the first 5 observations using a simple manually defined Distance Metric

```{r include=FALSE, echo=FALSE, comment=NA, warning=FALSE, fig.align='center', message=FALSE}
Manual_Pairwise=apply(head(ProjectData_segment,5),1,function(i) apply(head(ProjectData_segment,5),1,function(j) My_Distance_function(i,j) ))
Manual_Pairwise <- Manual_Pairwise * lower.tri(Manual_Pairwise) + Manual_Pairwise * diag(Manual_Pairwise) + 10e10*upper.tri(Manual_Pairwise)
Manual_Pairwise[Manual_Pairwise == 10e10] <- NA
```

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, fig.align='center', results='asis'}
print(xtable(Manual_Pairwise, caption="", digits=1), type="html", html.table.attributes = "class='table table-striped table-hover table-bordered'", caption.placement="top", comment = FALSE, include.rownames = FALSE)
```
</div>
</div>
</div>


Step 5. Visualize Pair-wise Distances 
========================================================

 Histogram of all pairwise distances 
========================================================

Distance Used:  `r distance_used` 
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, fig.align='center', results='asis'}
Pairwise_Distances <- dist(ProjectData_segment, method = distance_used) 
hist(Pairwise_Distances, main = NULL, xlab="Histogram of all pairwise Distances between observtions", ylab="Frequency")
```


 Step 6. Method and Number of Segments
========================================================

<br>
<br>

There are many clustering methods. Two common ones are:

* Hierarchical Methods

* Non-Hierarchical Methods (e.g. k-means)

<br>

We can plug-and-play (with CARE) this "black box" in our analysis 

 Hierarchical Clustering: Dendrogram
========================================================

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, fig.align='center', results='asis'}
Hierarchical_Cluster_distances <- dist(ProjectData_segment, method=distance_used)
Hierarchical_Cluster <- hclust(Hierarchical_Cluster_distances, method=hclust_method)
# Display dendogram
plot(Hierarchical_Cluster, main = NULL, sub=NULL, labels = 1:nrow(ProjectData_segment), xlab="Our Observations", cex.lab=1, cex.axis=1) 
# Draw dendogram with red borders around the 3 clusters
rect.hclust(Hierarchical_Cluster, k=numb_clusters_used, border="red") 
```
<div>

 Hierarchical Clustering Dendrogram Heights Plot
========================================================

<style>
.wrapper{
height: 40%;
width: 800px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:15px;">
```{r Fig1, echo=FALSE, comment=NA, results='asis', message=FALSE, fig.align='center', fig=TRUE}
max <- nrow(ProjectData)
num <- max - 1
df1 <- cbind(as.data.frame(Hierarchical_Cluster$height[length(Hierarchical_Cluster$height):1]), c(1:num))
colnames(df1) <- c("distances","index")
Line <- gvisLineChart(as.data.frame(df1), xvar="index", yvar="distances", options=list(title='Distances plot', legend="right", width=900, height=600, hAxis="{title:'Number of Components', titleTextStyle:{color:'black'}}", vAxes="[{title:'Distances'}]", series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(Line,'chart')
```
<div>

 Cluster Membership: Hierarchical Clustering
========================================================

<br>

```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
cluster_memberships_hclust <- as.vector(cutree(Hierarchical_Cluster, k=numb_clusters_used)) # cut tree into 3 clusters
cluster_ids_hclust=unique(cluster_memberships_hclust)
ProjectData_with_hclust_membership <- cbind(1:length(cluster_memberships_hclust),cluster_memberships_hclust)
colnames(ProjectData_with_hclust_membership)<-c("Observation Number","Cluster_Membership")
```


<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
show_data = data.frame(round(ProjectData_with_hclust_membership,2))
show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Observation"
colnames (dfnew)<-change
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
print(m1,'chart')
```
</div>
</div>
</div>

 Cluster Membership: K-means Clustering
========================================================

Note: K-means does not necessarily lead to the same solution every time you run it


```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
kmeans_clusters <- kmeans(ProjectData_segment,centers= numb_clusters_used, iter.max=2000, algorithm=kmeans_method)

ProjectData_with_kmeans_membership <- cbind(1:length(kmeans_clusters$cluster),kmeans_clusters$cluster)
colnames(ProjectData_with_kmeans_membership)<-c("Observation Number","Cluster_Membership")
```


<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
show_data = data.frame(round(ProjectData_with_kmeans_membership,2))
show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Observation"
colnames (dfnew)<-change
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
print(m1,'chart')
```
</div>
</div>
</div>

 Step 7. Profile and interpret the segments 
========================================================

<br>
<br>
<br>

Data analytics is used to eventually make decisions, and that is feasible only when we are comfortable (enough) with our understanding of the analytics results, including our ability to clearly interpret them. 

 Cluster Profiling: Cluster Centers of Profling Variables
========================================================


<br>

```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
cluster_memberships_kmeans <- kmeans_clusters$cluster 
cluster_ids_kmeans <- unique(cluster_memberships_kmeans)
```

```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}

cluster_memberships <- cluster_memberships_hclust
cluster_ids <-  cluster_ids_hclust  
if (profile_with == "hclust"){
  cluster_memberships <- cluster_memberships_hclust
  cluster_ids <-  cluster_ids_hclust  
  }
if (profile_with == "kmeans"){
  cluster_memberships <- cluster_memberships_kmeans
  cluster_ids <-  cluster_ids_kmeans
  }

population_average = matrix(apply(ProjectData_profile, 2, mean), ncol=1)
colnames(population_average) <- "Population"
Cluster_Profile_mean <- sapply(sort(cluster_ids), function(i) apply(ProjectData_profile[(cluster_memberships==i), ], 2, mean))
if (ncol(ProjectData_profile) <2)
  Cluster_Profile_mean=t(Cluster_Profile_mean)
colnames(Cluster_Profile_mean) <- paste("Segment", 1:length(cluster_ids), sep=" ")
cluster.profile <- cbind (population_average,Cluster_Profile_mean)
```

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, results='asis'}
show_data = data.frame(round(cluster.profile,2))
#show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Variables"
colnames (dfnew)<-change
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
print(m1,'chart')

```
</div>
</div>
</div>

 Interpretation: Snake Plots
========================================================

<style>
.wrapper{
height: 160%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
```{r Fig2, fig.width=6, fig.height=6, message=FALSE, echo=FALSE, fig.align='center', warning=FALSE, fig=TRUE}
ProjectData_scaled=apply(ProjectData,2, function(r) {if (sd(r)!=0) res=(r-mean(r))/sd(r) else res=0*r; res})
ProjectData_scaled_profile = ProjectData_scaled[, profile_attributes_used,drop=F]

Cluster_Profile_standar_mean <- sapply(sort(cluster_ids), function(i) apply(ProjectData_scaled_profile[(cluster_memberships==i), ,drop = F], 2, mean))
if (ncol(ProjectData_scaled_profile) < 2)
  Cluster_Profile_standar_mean = t(Cluster_Profile_standar_mean)
colnames(Cluster_Profile_standar_mean) <- paste("Segment", 1:length(cluster_ids), sep=" ")

plot(Cluster_Profile_standar_mean[, 1,drop=F], type="l", col="red", main="Snake plot for each cluster", ylab="mean of cluster", xlab="profiling variables (standardized)",ylim=c(min(Cluster_Profile_standar_mean),max(Cluster_Profile_standar_mean))) 
for(i in 2:ncol(Cluster_Profile_standar_mean))
  lines(Cluster_Profile_standar_mean[, i], col="blue")
```
</div>


 Interpretation: Ratio to Average of Total Population -1 (0 = Average)
========================================================


```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, results='asis'}
population_average_matrix <- population_average[,"Population",drop=F] %*% matrix(rep(1,ncol(Cluster_Profile_mean)),nrow=1)
cluster_profile_ratios <- (ifelse(population_average_matrix==0, 0,Cluster_Profile_mean/population_average_matrix-1))
colnames(cluster_profile_ratios) <- paste("Segment", 1:ncol(cluster_profile_ratios), sep=" ")
rownames(cluster_profile_ratios) <- colnames(ProjectData)[profile_attributes_used]
## printing the result in a clean-slate table
```

<style>
.wrapper{
height: 120%;
width: 900px;
overflow: auto;
}
</style>
<div class="wrapper" style="font-size:20px;">
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, results='asis'}
show_data = data.frame(round(cluster_profile_ratios,2))
#show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Variables"
colnames (dfnew)<-change
m1<-gvisTable(dfnew,options=list(showRowNumber=TRUE,width=1220, height=400,allowHTML=TRUE,page='disable'))
show_data = data.frame(round(cluster_profile_ratios,2))
m1<-gvisTable(show_data,options=list(width=1920, height=min(400,27*(nrow(show_data)+1)),allowHTML=TRUE))
print(m1,'chart')
#cat(renderHeatmapX(cluster_profile_ratios, border=1, center = 1, minvalue = heatmin))
```
</div>
</div>
</div>

 The data
========================================================

V1: Shopping is fun (scale 1-7)

V2: Shopping is bad for your budget (scale 1-7)

V3: I combine shopping with eating out (scale 1-7)

V4: I try to get the best buys while shopping (scale 1-7)

V5: I don't care about shopping (scale 1-7)

V6: You can save lot of money by comparingprices (scale 1-7)

Income: the household income of the respondent (in dollars)

Mall.Visits: how often they visit the mall (scale 1-7)


 Step 8. Robustness Analysis
========================================================

<br>

Are the clusters stable when we use:
<br>

- using different subsets of the original data
- using variations of the original segmentation attributes
- using different distance metrics
- using different segmentation methods
- using different numbers of clusters


 Example Robustness Test: Different Methods
========================================================


```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, results='asis'}
# First, make sure the segment ids are correctly aligned
cluster_overlaps <- Reduce(cbind,lapply(1:length(cluster_ids_kmeans), function(i) {
  overlaps <- sapply(1:length(cluster_ids_hclust), function(j) {
    length(intersect(which(cluster_memberships_kmeans==i), 
                     which(cluster_memberships_hclust==j))) } );
  overlaps}))
max_cluster_overlap = rep(0,length(cluster_ids_kmeans))
for (i in 1:length(cluster_ids_kmeans)){
  highest_now = which.max(cluster_overlaps)
  hclust_id_now = highest_now %% length(cluster_ids_kmeans)
  hclust_id_now = ifelse(hclust_id_now == 0, 3, hclust_id_now)
  kmeans_id_now = ceiling(highest_now/length(cluster_ids_kmeans))
  max_cluster_overlap[kmeans_id_now] <- hclust_id_now
  cluster_overlaps[hclust_id_now,] <- 0
  cluster_overlaps[,kmeans_id_now] <- 0
}
cluster_memberships_kmeans_aligned <- rep(0,length(cluster_memberships_kmeans))
for (i in 1:length(cluster_ids_kmeans))
  cluster_memberships_kmeans_aligned[(cluster_memberships_kmeans==i)] <- max_cluster_overlap[i]

# Now calculate the overlaps
# First, the total overlap
total_observations_overlapping <- 100*sum(cluster_memberships_kmeans_aligned==cluster_memberships_hclust) / length(cluster_memberships_hclust)
# Then, per cluster
per_cluster_observations_overlapping <- sapply(1:length(cluster_ids_kmeans), function(i) 100*length(intersect(which(cluster_memberships_kmeans_aligned==i),which(cluster_memberships_hclust==i)))/sum(cluster_memberships_kmeans_aligned==i))
per_cluster_observations_overlapping <- matrix(per_cluster_observations_overlapping, nrow=1)
colnames(per_cluster_observations_overlapping) <- paste("Segment",1:length(per_cluster_observations_overlapping),sep=" ")
```

<br>

The percentage of observations belonging to the same segment is
<div class="row">
<div class="col-md-3">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, fig.align='center', results='asis'}
print(xtable(per_cluster_observations_overlapping, caption = paste(paste("", total_observations_overlapping, sep=" "), "%."), digits=1), type="html", html.table.attributes = "class='table table-striped table-hover table-bordered'", caption.placement="top", comment = FALSE, include.rownames = FALSE)
```
</div>
</div>
<br>

How much overlap should we expect across clustering solutions?


 Key Technical Terms and Lessons
========================================================

- Segmentation Variables
- Profiling Variables
- Distance Metrics
- Hierarchical Clustering
- Dendrogram
- K-means Clustering
- Robustness: Statistics, Interpretation, Decisions
- Actionability, Interpretability, Statistical Robustness

 Group Work
========================================================

1. How many market segments (clusters) are there? Why?

2. How would you describe the segments?

3. How would the segments inform the strategy of CreeqBoat?


