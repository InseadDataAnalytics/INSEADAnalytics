---
title : Data Analytics for Business
subtitle : Session 6-7, Classification
author : T. Evgeniou 
job : INSEAD
widgets : []
mode : standalone 
---

## Example Applications

- Which molecules are most likely to succeed for the drug?
- Whose DNA is most likely to indicate future health problems of a particular type?
- Who are the most likely clients/companies/countries to default on their debt?
- Who are most likely to click on an ad? 
- To whom should we offer a particular promotion?
- How are satisfied customers different from dissatisfied customers in terms of their demographics and attitudes towards your productsâ€™ characteristics?
- Which transaction is most likely a fraud?
- Which applicants are most likely to fit in our organization and succeed?
- Which investments are most likely to succeed?

---

## What is common to these problems?

1. There is a dependent variable which is categorical e.g. success vs failure (fit vs. non-fit; fraud vs. non-fraud, response vs. non-response, etc.)

2. There are some independent variables which we can use to explain membership in the different categories

---

## Example: Boats Purchase Drivers

Who would be the most likely customers to purchase a boat in the future or to recommend their brand?

What would be the **key drivers** that affect people's decision to purchase or recommend?

---
## Various Methods

- Logistic regression
- Classification trees
- Boosted Trees
- Nearest Neighbors
- Neural Networks
- Bayesian methods
- Support Vector Machines
- Deep learning methods
- others...

---


## Classification: A Process

1. Create an estimation and two validation samples in a balanced way 
2. Setup the dependent variable (what is a success?)
3. Assess and select the independent variables
4. Estimate model (many methods, we consider only 2 here)
5. Assess performance on first validation data, repeat steps 2-5 as necessary
6. Assess performance on second validation data once

---

## Data Splits: Example Split

Estimation Data: `r estimation_data_percent`% of the data

Validation Data: `r validation_data_percent`% of the data

Test Data: `r 100 - estimation_data_percent - validation_data_percent`% of the data

```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}

if (random_sampling){
  estimation_data_ids=sample.int(nrow(ProjectData),floor(estimation_data_percent*nrow(ProjectData)/100))
  non_estimation_data = setdiff(1:nrow(ProjectData),estimation_data_ids)
  validation_data_ids=non_estimation_data[sample.int(length(non_estimation_data), floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(non_estimation_data)))]
  } else {
    estimation_data_ids=1:floor(estimation_data_percent*nrow(ProjectData)/100)
    non_estimation_data = setdiff(1:nrow(ProjectData),estimation_data_ids)
    validation_data_ids = (tail(estimation_data_ids,1)+1):(tail(estimation_data_ids,1) + floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(non_estimation_data)))
    }

test_data_ids = setdiff(1:nrow(ProjectData), union(estimation_data_ids,validation_data_ids))

estimation_data=ProjectData[estimation_data_ids,]
validation_data=ProjectData[validation_data_ids,]
test_data=ProjectData[test_data_ids,]
```

---

## Example: Some Data
<style>
.wrapper{


width: 100%;

overflow-x: scroll;

}
.wrapper1{

height:450px;
overflow-y: scroll;
}
</style>
<div class="wrapper wrapper1">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='asis'}
show_data = data.frame(round(ProjectData[,independent_variables],2))
show_data = show_data[1:min(max_data_report,nrow(show_data)),]
row<-rownames(show_data)
dfnew<-cbind(row,show_data)
change<-colnames(dfnew)
change[1]<-"Variables"
colnames (dfnew)<-change
#m1<-gvisTable(dfnew,options=list(showRowNumber=FALSE,width=960, height=440,allowHTML=TRUE,page='disable'))
#print(m1,'chart')
print(xtable(dfnew ,caption="Number of Observations per class in the Estimation Sample", digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE,include.rownames = TRUE)
```
</div>

---

## CART: Classification Trees


```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}

independent_variables_nolabel = paste("IV", 1:length(independent_variables), sep="")

estimation_data_nolabel = cbind(estimation_data[,dependent_variable], estimation_data[,independent_variables])
colnames(estimation_data_nolabel)<- c(colnames(estimation_data)[dependent_variable],independent_variables_nolabel)

validation_data_nolabel = cbind(validation_data[,dependent_variable], validation_data[,independent_variables])
colnames(validation_data_nolabel)<- c(dependent_variable,independent_variables_nolabel)

test_data_nolabel = cbind(test_data[,dependent_variable], test_data[,independent_variables])
colnames(test_data_nolabel)<- c(dependent_variable,independent_variables_nolabel)

estimation_data_nolabel = data.frame(estimation_data_nolabel)
validation_data_nolabel = data.frame(validation_data_nolabel)
test_data_nolabel = data.frame(test_data_nolabel)

estimation_data = data.frame(estimation_data)
validation_data = data.frame(validation_data)
test_data = data.frame(test_data)

```
<center>
```{r echo=FALSE, message=FALSE, warning=FALSE,prompt=FALSE, results='asis'}
formula=paste(colnames(estimation_data)[dependent_variable],paste(Reduce(paste,sapply(head(independent_variables_nolabel,-1), function(i) paste(i,"+",sep=""))),tail(independent_variables_nolabel,1),sep=""),sep="~")
CART_tree<-rpart(formula, data= estimation_data_nolabel,method="class", control=CART_control)

fancyRpartPlot(CART_tree)
```
</center>

---

## Another Classification Tree

<center>
```{r echo=FALSE, warning=FALSE,message=FALSE, prompt=FALSE, results='asis'}
CART_tree_large<-rpart(formula, data= estimation_data_nolabel,method="class", control=rpart.control(cp = 0.005))

fancyRpartPlot(CART_tree_large)
```
</center>

---

## KEY QUESTION: Model Complexity

Do we want a "large" or a "small" tree? 

How complex should our classifier be?


```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
# Let's first calculate all probabilites for the estimation, validation, and test data
estimation_Probability_class1_tree<-predict(CART_tree, estimation_data_nolabel)[,2]
estimation_Probability_class1_tree_large<-predict(CART_tree_large, estimation_data_nolabel)[,2]

validation_Probability_class1_tree<-predict(CART_tree, validation_data_nolabel)[,2]
validation_Probability_class1_tree_large<-predict(CART_tree_large, validation_data_nolabel)[,2]

test_Probability_class1_tree<-predict(CART_tree, test_data_nolabel)[,2]
test_Probability_class1_tree_large<-predict(CART_tree_large, test_data_nolabel)[,2]


estimation_prediction_class_tree=1*as.vector(estimation_Probability_class1_tree > Probability_Threshold)
estimation_prediction_class_tree_large=1*as.vector(estimation_Probability_class1_tree_large > Probability_Threshold)

validation_prediction_class_tree=1*as.vector(validation_Probability_class1_tree > Probability_Threshold)
validation_prediction_class_tree_large=1*as.vector(validation_Probability_class1_tree_large > Probability_Threshold)

test_prediction_class_tree=1*as.vector(test_Probability_class1_tree > Probability_Threshold)
test_prediction_class_tree_large=1*as.vector(test_Probability_class1_tree_large > Probability_Threshold)

```

```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}

Classification_Table=rbind(validation_data[,dependent_variable],validation_Probability_class1_tree)
rownames(Classification_Table)<-c("Actual Class","Probability of Class 1")
colnames(Classification_Table)<- paste("Obs", 1:ncol(Classification_Table), sep=" ")

Classification_Table_large=rbind(validation_data[,dependent_variable],validation_Probability_class1_tree)
rownames(Classification_Table_large)<-c("Actual Class","Probability of Class 1")
colnames(Classification_Table_large)<- paste("Obs", 1:ncol(Classification_Table_large), sep=" ")

```

---

## Logistic Regression

<style>
.wrapper{
            
            
            width: 100%;
           
            overflow-x: scroll;
             
          }
.wrapper1{
            
           height:400px;
             overflow-y: scroll;
          }
</style>
<div class="wrapper wrapper1">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}

formula_log=paste(colnames(estimation_data[,dependent_variable,drop=F]),paste(Reduce(paste,sapply(head(independent_variables,-1), function(i) paste(colnames(estimation_data)[i],"+",sep=""))),colnames(estimation_data)[tail(independent_variables,1)],sep=""),sep="~")

logreg_solution <- glm(formula_log, family=binomial(link="logit"),  data=estimation_data)

log_coefficients = round(summary(logreg_solution)$coefficients,1)
print(xtable(log_coefficients,caption="Logistic Regression: Estimated Coefficients" , digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE,include.rownames = TRUE)

```
</div>

```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
# Let's get the probabilities for the 3 types of data again
estimation_Probability_class1_log<-predict(logreg_solution, type="response", newdata=estimation_data[,independent_variables])
validation_Probability_class1_log<-predict(logreg_solution, type="response", newdata=validation_data[,independent_variables])
test_Probability_class1_log<-predict(logreg_solution, type="response", newdata=test_data[,independent_variables])

estimation_prediction_class_log=1*as.vector(estimation_Probability_class1_log > Probability_Threshold)
validation_prediction_class_log=1*as.vector(validation_Probability_class1_log > Probability_Threshold)
test_prediction_class_log=1*as.vector(test_Probability_class1_log > Probability_Threshold)

```

---

## Drivers Analysis

<style>
.wrapper{
            
            
            width: 100%;
           
            overflow-x: scroll;
             
          }
.wrapper1{
            
           height:400px;
             overflow-y: scroll;
          }
</style>
<div class="wrapper wrapper1">
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE, results='asis'}
log_importance = tail(log_coefficients[,"z value", drop=F],-1) # remove the intercept
log_importance = log_importance/max(abs(log_importance))

tree_importance = CART_tree$variable.importance
tree_ordered_drivers = as.numeric(gsub("\\IV"," ",names(CART_tree$variable.importance)))
tree_importance_final = rep(0,length(independent_variables))
tree_importance_final[tree_ordered_drivers] <- tree_importance
tree_importance_final <- tree_importance_final/max(abs(tree_importance_final))
tree_importance_final <- tree_importance_final*sign(log_importance)

large_tree_importance = CART_tree_large$variable.importance
large_tree_ordered_drivers = as.numeric(gsub("\\IV"," ",names(CART_tree_large$variable.importance)))
large_tree_importance_final = rep(0,length(independent_variables))
large_tree_importance_final[large_tree_ordered_drivers] <- large_tree_importance
large_tree_importance_final <- large_tree_importance_final/max(abs(large_tree_importance_final))
large_tree_importance_final <- large_tree_importance_final*sign(log_importance)

Importance_table <- cbind(tree_importance_final,large_tree_importance_final, log_importance)
colnames(Importance_table) <- c("CART 1", "CART 2", "Logistic Regr.")
rownames(Importance_table) <- rownames(log_importance)
## printing the result in a clean-slate table
cat(renderHeatmapX(Importance_table, border=1, center = 0, minvalue = 0))
```
</div>

---

## Hit Ratio: Validation Data
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
validation_actual=validation_data[,dependent_variable]
validation_predictions = rbind(validation_prediction_class_tree,
                               validation_prediction_class_tree_large,
                               validation_prediction_class_log)
validation_hit_rates = rbind(
  100*sum(validation_prediction_class_tree==validation_actual)/length(validation_actual), 
  100*sum(validation_prediction_class_tree_large==validation_actual)/length(validation_actual), 
  100*sum(validation_prediction_class_log==validation_actual)/length(validation_actual)
  )
colnames(validation_hit_rates) <- "Hit Ratio"
rownames(validation_hit_rates) <- c("First CART", "Second CART", "Logistic Regression")

print(xtable(validation_hit_rates ,caption="Validation Data Hit Ratios for different classifiers tested", digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE,include.rownames = TRUE)

```
</div>
</div>

---

## Hit Ratio: Estimation Data
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
estimation_actual=estimation_data[,dependent_variable]
estimation_predictions = rbind(estimation_prediction_class_tree,
                               estimation_prediction_class_tree_large,
                               estimation_prediction_class_log)
estimation_hit_rates = rbind(
  100*sum(estimation_prediction_class_tree==estimation_actual)/length(estimation_actual), 
  100*sum(estimation_prediction_class_tree_large==estimation_actual)/length(estimation_actual), 
  100*sum(estimation_prediction_class_log==estimation_actual)/length(estimation_actual)
  )
colnames(estimation_hit_rates) <- "Hit Ratio"
rownames(estimation_hit_rates) <- c("First CART", "Second CART", "Logistic Regression")

print(xtable(estimation_hit_rates ,caption="Estimation Data Hit Ratios for different classifiers tested", digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE,include.rownames = TRUE)
```
</div>
</div>

---

## Fit versus Prediction

Should the performance of our model be similar in the estimation and validation data? 

How about when we deploy the model?

Why should performance be different? Why should it not? What can we do about it?


---

## Hit Ratios: Test Data for best validation hit rate method
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
test_actual=test_data[,dependent_variable]
test_predictions = rbind(test_prediction_class_tree,
                         test_prediction_class_tree_large,
                         test_prediction_class_log)
test_hit_rates = rbind(
  100*sum(test_prediction_class_tree==test_actual)/length(test_actual), 
  100*sum(test_prediction_class_tree_large==test_actual)/length(test_actual), 
  100*sum(test_prediction_class_log==test_actual)/length(test_actual)
  )
colnames(test_hit_rates) <- "Hit Ratio"
rownames(test_hit_rates) <- c("First CART", "Second CART", "Logistic Regression")

print(xtable(test_hit_rates ,caption="Test Data Hit Ratios for different classifiers tested", digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE,include.rownames = TRUE)

```
</div>
</div>

---

## Confusion Matrix: Test Data
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
test_prediction_best = test_predictions[which.max(validation_hit_rates),]
conf_matrix = matrix(rep(0,4),ncol=2)
conf_matrix[1,1]<- 100*sum(test_prediction_best*test_data[,dependent_variable])/sum(test_data[,dependent_variable])
conf_matrix[1,2]<- 100*sum((!test_prediction_best)*test_data[,dependent_variable])/sum(test_data[,dependent_variable])
conf_matrix[2,1]<- 100*sum((!test_prediction_best)*(!test_data[,dependent_variable]))/sum((!test_data[,dependent_variable]))
conf_matrix[2,2]<- 100*sum((test_prediction_best)*(!test_data[,dependent_variable]))/sum((!test_data[,dependent_variable]))
conf_matrix = round(conf_matrix,2)

colnames(conf_matrix) <- c("Predicted 1", "Predicted 0")
rownames(conf_matrix) <- c("Actual 1", "Actual 0")

print(xtable(conf_matrix ,caption="Confusion Matrix for test data", digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE)
```
</div>
</div>

---

## ROC Curves: Test Data

(black: CART 1; red: CART 2; blue: logistic regression):


```{r echo=FALSE,results='hide',include=FALSE,warning=FALSE,error=FALSE}

test_actual_class <- as.numeric(test_data[,dependent_variable])

pred_tree_test <- prediction(test_Probability_class1_tree, test_actual_class)
pred_tree_large_test <- prediction(test_Probability_class1_tree_large, test_actual_class)
pred_log_test <- prediction(test_Probability_class1_log, test_actual_class)
```


```{r echo=FALSE}
plot(performance(pred_tree_large_test, "tpr", "fpr"), col="red", lty=1, add=FALSE)
grid()
par(new=TRUE)
plot(performance(pred_log_test, "tpr", "fpr"), col="blue", lty=1, add=FALSE)
par(new=TRUE)
plot(performance(pred_tree_test, "tpr", "fpr"),  lty=1, add=FALSE, main="ROC Curve")
par(new=FALSE)

```

---

## Lift Curves: Test Data


<style>
.wrapper{
            
            
            width: 100%;
           
            overflow-x: scroll;
             
          }
.wrapper1{
            
           height:450px;
             overflow-y: scroll;
          }
</style>
<div class="wrapper wrapper1">

```{r liftTest,echo=FALSE,results='asis',warning=FALSE,error=FALSE}
test_actual<- test_data[,dependent_variable]
all1s = sum(test_actual)

probs = test_Probability_class1_tree
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = 100*Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= 1-prob)
  c(length(useonly)/length(test_actual), sum(test_actual[useonly])/all1s) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFrame   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Lift Curve for test data CART', legend="right", width=600, height=400, hAxis="{title:'Percent of data', titleTextStyle:{color:'black'}}", vAxes="[{title:' Percent of Class 1'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFrame,'chart')

probs = test_Probability_class1_tree_large
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = 100*Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= 1-prob)
  c(length(useonly)/length(test_actual), sum(test_actual[useonly])/all1s) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFrame1   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Lift Curve for test data CART large', legend="right", width=600, height=400, hAxis="{title:'Percent of data', titleTextStyle:{color:'black'}}", vAxes="[{title:'Percent of Class 1'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFrame1,'chart')

probs = test_Probability_class1_log
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = 100*Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= 1-prob)
  c(length(useonly)/length(test_actual), sum(test_actual[useonly])/all1s) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFrame2  <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Lift Curve for test data CART large', legend="right", width=600, height=400, hAxis="{title:'Percent of data', titleTextStyle:{color:'black'}}", vAxes="[{title:'Percent of Class 1'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFrame2,'chart')

```
</div>

---

## Profit Matrix
<div class="row">
<div class="col-md-6">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}

print(xtable(Profit_Matrix ,caption="Assumed Profits and Costs", digits=1,),type="html",html.table.attributes = "class='table table-striped table-hover table-bordered'",caption.placement="top",comment = FALSE,include.rownames = TRUE)

```
</div>
</div>

---

## Profit Curves: Test Data

<style>
.wrapper{
            
            
            width: 100%;
           
            overflow-x: scroll;
             
          }
.wrapper1{
            
           height:450px;
             overflow-y: scroll;
          }
</style>
<div class="wrapper wrapper1">

```{r echo=FALSE, warning=FALSE,comment=NA, results='asis',error=FALSE,message=FALSE}
actual_class<- test_data[,dependent_variable]

probs = test_Probability_class1_tree
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= prob)
  predict_class = 1*(probs >= prob)
  theprofit = Profit_Matrix[1,1]*sum(predict_class==1 & actual_class ==1)+
    Profit_Matrix[1,2]*sum(predict_class==0 & actual_class ==1)+
    Profit_Matrix[2,1]*sum(predict_class==1 & actual_class ==0)+
    Profit_Matrix[2,2]*sum(predict_class==0 & actual_class ==0)
  
  c(100*length(useonly)/length(actual_class), theprofit) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFramev1   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Profit Curve for test data CART 1', legend="right", width=600, height=600, hAxis="{title:'Percent Selected', titleTextStyle:{color:'black'}}", vAxes="[{title:'Estimated Profit'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFramev1,'chart')

probs = test_Probability_class1_tree_large
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= prob)
  predict_class = 1*(probs >= prob)
  theprofit = Profit_Matrix[1,1]*sum(predict_class==1 & actual_class ==1)+
    Profit_Matrix[1,2]*sum(predict_class==0 & actual_class ==1)+
    Profit_Matrix[2,1]*sum(predict_class==1 & actual_class ==0)+
    Profit_Matrix[2,2]*sum(predict_class==0 & actual_class ==0)
  
  c(100*length(useonly)/length(actual_class), theprofit) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFramev2   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Profit Curve for test data CART 2', legend="right", width=600, height=400, hAxis="{title:'Percent Selected', titleTextStyle:{color:'black'}}", vAxes="[{title:'Estimated Profit'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFramev2,'chart')

probs = test_Probability_class1_log
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= prob)
  predict_class = 1*(probs >= prob)
  theprofit = Profit_Matrix[1,1]*sum(predict_class==1 & actual_class ==1)+
    Profit_Matrix[1,2]*sum(predict_class==0 & actual_class ==1)+
    Profit_Matrix[2,1]*sum(predict_class==1 & actual_class ==0)+
    Profit_Matrix[2,2]*sum(predict_class==0 & actual_class ==0)
  
  c(100*length(useonly)/length(actual_class), theprofit) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFramev3   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Profit Curve for test data logistic regression', legend="right", width=600, height=400, hAxis="{title:'Percent Selected', titleTextStyle:{color:'black'}}", vAxes="[{title:'Estimated Profit'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFramev3,'chart')
```
</div>

---

## Segment Specific Drivers Analysis


What if we do the same analysis but for each segment separately? 

Does it make sense to do so? Why?

---

## Segment Specific Drivers Analysis

<style>
.wrapper{
            
            
            width: 100%;
           
            overflow-x: scroll;
             
          }
.wrapper1{
            
           height:400px;
             overflow-y: scroll;
          }
</style>
<div class="wrapper wrapper1">
```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
numb_clusters_used = 5

cluster_file = paste(paste(local_directory,"data", sep="/"),paste(paste(datafile_name,paste("cluster",numb_clusters_used,sep="") , sep="_"), "csv", sep="."), sep="/")

cluster_ids <- read.csv(cluster_file, sep=",", dec=".") # this contains only the matrix ProjectData
cluster_ids <- data.matrix(cluster_ids)
cluster_ids = cluster_ids[,2]

actual_class<- test_data[,dependent_variable]
probs_tree = 0*test_Probability_class1_tree
probs_tree_large = 0*test_Probability_class1_tree_large
probs_log = 0*test_Probability_class1_log
Log_Drivers = NULL

for (i in sort(unique(cluster_ids))){
  useonly = which(cluster_ids==i)
  if (length(useonly) >= min_segment){
    
    test_ids_used = intersect(test_data_ids,useonly)
    probs_to_fill = which(sapply(test_data_ids, function(i) sum(test_ids_used==i)) !=0)
    estimation_data_clus=ProjectData[intersect(estimation_data_ids,useonly) ,]
    test_data_clus=ProjectData[intersect(test_data_ids,useonly),]
    
    ###
    estimation_data_clus_nolabel = cbind(estimation_data_clus[,dependent_variable], estimation_data_clus[,independent_variables])
    colnames(estimation_data_clus_nolabel)<- c(colnames(estimation_data_clus)[dependent_variable],independent_variables_nolabel)
    
    test_data_clus_nolabel = cbind(test_data_clus[,dependent_variable], test_data_clus[,independent_variables])
    colnames(test_data_clus_nolabel)<- c(dependent_variable,independent_variables_nolabel)
    
    estimation_data_clus = data.frame(estimation_data_clus)
    test_data_clus = data.frame(test_data_clus)
    estimation_data_clus_nolabel = data.frame(estimation_data_clus_nolabel)
    test_data_clus_nolabel = data.frame(test_data_clus_nolabel)
    ###
    
    CART_tree<-rpart(formula, data= estimation_data_clus_nolabel,method="class", control=CART_control)    
    CART_tree_large<-rpart(formula, data= estimation_data_clus_nolabel,method="class", control=rpart.control(cp = 0.005))
    logreg_solution <- glm(formula_log, family=binomial(link="logit"), data=estimation_data_clus)
    
    #####
    
    test_Probability_class1_tree<-predict(CART_tree, test_data_clus_nolabel)[,2]
    test_Probability_class1_tree_large<-predict(CART_tree_large, test_data_clus_nolabel)[,2]
    test_Probability_class1_log<-predict(logreg_solution, type="response", newdata=test_data_clus[,independent_variables])
    
    #######
    probs_tree[probs_to_fill] <- test_Probability_class1_tree
    probs_tree_large[probs_to_fill] <- test_Probability_class1_tree
    probs_log[probs_to_fill] <- test_Probability_class1_log
    
    
    log_coefficients = round(summary(logreg_solution)$coefficients,1)
    Log_Drivers_segment = tail(log_coefficients[,"z value", drop=F],-1) # remove the intercept
    Log_Drivers_segment = Log_Drivers_segment/max(abs(Log_Drivers_segment))
    
    tree_importance = CART_tree$variable.importance
    tree_ordered_drivers = as.numeric(gsub("\\IV"," ",names(CART_tree$variable.importance)))
    tree_importance_final = rep(0,length(independent_variables))
    tree_importance_final[tree_ordered_drivers] <- tree_importance
    tree_importance_final <- tree_importance_final/max(abs(tree_importance_final))
    tree_importance_final <- tree_importance_final*sign(Log_Drivers_segment)
    
    #Log_Drivers = cbind(Log_Drivers,tree_importance_final)
    Log_Drivers = cbind(Log_Drivers,Log_Drivers_segment)
    
    
    }
  }
colnames(Log_Drivers) <- paste("Segment", 1:length(unique(cluster_ids)), sep = " ")
cat(renderHeatmapX(tail(Log_Drivers,-1), border=1, center = 0, minvalue = 0))

```
</div>


---

## Segment Specific Profit Curves: Test Data

Expected revenues can increase by 15% in this case: Is that a good number?

<style>
.wrapper{
            
            
            width: 100%;
           
            overflow-x: scroll;
             
          }
.wrapper1{
            
           height:450px;
             overflow-y: scroll;
          }
</style>
<div class="wrapper wrapper1">

```{r echo=FALSE, warning=FALSE,comment=NA, results='asis',error=FALSE,message=FALSE}
actual_class<- test_data[,dependent_variable]

probs = probs_tree
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= prob)
  predict_class = 1*(probs >= prob)
  theprofit = Profit_Matrix[1,1]*sum(predict_class==1 & actual_class ==1)+
    Profit_Matrix[1,2]*sum(predict_class==0 & actual_class ==1)+
    Profit_Matrix[2,1]*sum(predict_class==1 & actual_class ==0)+
    Profit_Matrix[2,2]*sum(predict_class==0 & actual_class ==0)
  
  c(100*length(useonly)/length(actual_class), theprofit) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFramev1   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Profit Curve for test data CART 1', legend="right", width=600, height=600, hAxis="{title:'Percent Selected', titleTextStyle:{color:'black'}}", vAxes="[{title:'Estimated Profit'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFramev1,'chart')

probs = probs_tree_large
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= prob)
  predict_class = 1*(probs >= prob)
  theprofit = Profit_Matrix[1,1]*sum(predict_class==1 & actual_class ==1)+
    Profit_Matrix[1,2]*sum(predict_class==0 & actual_class ==1)+
    Profit_Matrix[2,1]*sum(predict_class==1 & actual_class ==0)+
    Profit_Matrix[2,2]*sum(predict_class==0 & actual_class ==0)
  
  c(100*length(useonly)/length(actual_class), theprofit) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFramev2   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Profit Curve for test data CART 2', legend="right", width=600, height=400, hAxis="{title:'Percent Selected', titleTextStyle:{color:'black'}}", vAxes="[{title:'Estimated Profit'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFramev2,'chart')

probs = probs_log
xaxis = sort(unique(c(0,1,probs)), decreasing = TRUE)
res = Reduce(cbind,lapply(xaxis, function(prob){
  useonly = which(probs >= prob)
  predict_class = 1*(probs >= prob)
  theprofit = Profit_Matrix[1,1]*sum(predict_class==1 & actual_class ==1)+
    Profit_Matrix[1,2]*sum(predict_class==0 & actual_class ==1)+
    Profit_Matrix[2,1]*sum(predict_class==1 & actual_class ==0)+
    Profit_Matrix[2,2]*sum(predict_class==0 & actual_class ==0)
  
  c(100*length(useonly)/length(actual_class), theprofit) 
  }))
xaxis = res[1,]; yaxis = res[2,]
names(xaxis)<- NULL; names(yaxis) <- NULL
frame<-cbind(xaxis,yaxis)
frame<-as.data.frame(frame)
LineFramev3   <- gvisLineChart(frame, xvar=c("xaxis"), yvar="yaxis", options=list(title='Profit Curve for test data logistic regression', legend="right", width=600, height=400, hAxis="{title:'Percent Selected', titleTextStyle:{color:'black'}}", vAxes="[{title:'Estimated Profit'}]",  series="[{color:'green',pointSize:3, targetAxisIndex: 0}]"))
print(LineFramev3,'chart')
```
</div>

---

## Iterative Data Analytics Processes

Does segment specific analysis help for our business decisions? 

Which solution should we use? 

Should we explore a different solution? 

Should we re-start from data collection, factor analysis, segmentation, or classification and drivers' analysis? 

How can the company use the final solution?

---

## Observations and Lessons

- Fitting data is very easy: prediction is the challenge
- Beware of overfitting: key risk
- Beware of changes in the statistics of the data
- Defining what "success" is can be crucial
- Segment specific analysis must be considered when data are heterogeneous (15% increase in revenues in this case)
- Contextual knowledge is absolutely necessary
- Many performance metrics available
- Deployment of classification models requires a number of managerial decisions
- Iterations are necessary: Efficiency, Replicability, Reusability are key
- Data Analytics requires a balance between quantitative and qualitative criteria: it is "Art AND Science"

--- 

## Next Class: Wrap Up
